%DescriptionModel

\subsection{General considerations}
As we wanted to describe a situation with people, we chose a model based on discrete agents. They should be able to walk freely along their path until they hit an obstacle, in which case they should be able to determine a way to avoid the obstacle. Obstacles could be walls, objects placed in the path or simply other agents. The main goal of any agent is to get to the other side of the path as quickly as possible, if possible without crashing into other things. As the global situation changes with each "step" an agents does and also with the appearance of new agents, a step-by-step iteration was chosen to propagate the situation in time in which the the optimal direction is calculated all the time. The other approach of calculating a certain path from start to finish was rejected as it probably cannot be done for the uncertainties mentioned above, namely the random appearance of new agents which could block the calculated path. Also, this is not a main point for our situation because there's not a specific destination an agent walks to, but a intended zone to go to. In a hallway without exits on the sides, the goal only is to traverse it.\\
Any agent's goal is to get to the other side as quickly as possible, although our model cannot accommodate the requirement of the quickest possible path. Because of the step-by-step iteration, any situation is repeatedly analyzed and (hopefully) the best way to proceed is chosen. As this is only a short time period and we only consider an agent's situation in a local environment, it cannot guarantee to give the best outcome overall. To make a long story short, we used a \textit{local search algorithm}.

\subsection{Walls and other static obstacles}
If a narrow hallway should be a narrow hallway, it needs two walls. Although this statement is obvious, it can be implemented in various ways. We chose to use static agents with a small radius to act as a wall, as it allows the creation of many different hallways. They can also be used as static objects representing obstacles like chairs and tables which could stand in the path an agent has to follow to get to the other side. For our simulation, this was a very flexible way which also allows a quick adaption to other situations if necessary.

\subsection{Agents}
The basis of the simulation is the agent. An agent should represent a person in real life. We assumed that the hallway was not a place to linger about, therefore they should try to get to the other side as quickly as possible. In order to do so, they need to be aware of all the things around them that they might bump into. This was the origin of the thought that any agents only looks forward as the obstacles will be in the path before them. In our model, they also need some intelligence to get around an obstacle and avoid running into other agents. To do so, the agent should consider all things within a circle of defined radius in front of him while everything else doesn't bother him. Again, this tries to get a local solution to our problem in the hope that the overall solution is still a good one. As one usually doesn't walk backwards, our agents only walk forwards. This might not be true for all situations but for most of the situations a pedestrian walks into, and it simplifies the model considerably. We also think that, if a pedestrian does only walk more or less forwards and won't be involved in a jam or collision, his passing time will be quite good compared a perfect chosen path, if a such path even exists.\\

\noi In comparison to previous models which used a force field to guide the agents, we thought that this approach is more realistic as the force field approach given that the force field already defines the optimal solution one is looking for. It should also prove to be more adaptable within a reasonable time frame to other problems.

\subsection{Intelligence}
\subsubsection{General considerations regarding the necessary intelligence}
For the model to work properly, a sensible solution to deal with the problem of finding the right path must be found. We do not claim to have found the best solution but believe our model to be a fairly good solution.\\
The presence of every other agent, be it agent or wall, inside a semi-circle in front of the currently considered agent clearly must have an influence in order not to bump into it. The fundamental idea is to get a function for every agent inside this agent's semi-circle which reproduces the effect it has on the path the considered agent would take without them being in his semi-circle. All of these functions will then be added and the maximum value would be taken as the best way to go forward. An additional function is added which should represent the tendency to go straight forward.\\

\noi All functions were calculated as functions of $x$. This $x$ is connected to an angle $\varphi$ given by $arctan(x)$. A value of $\varphi = -\pi/2$ would correspond to walking sideways to the left, $\varphi = 0$ to walk straight forward and $\varphi = \pi/2$ to walking sideways to the right, always viewed in the direction the agent wants to go.\\
A function calculated in $x$ will then be superimposed on $\varphi$ which corresponds to a mapping of the function onto a polar grid. A possible disadvantage of this procedure is that $\varphi$ does not range from $-\pi/2$ to $\pi/2$ and therefore doesn't reach the full semi-circle as $x$ is bounded and doesn't reach infinity. We consider this to be negligible as for reasonably high values of $x$, $\varphi$ gets close to $\pm \pi/2$ and it is rarely in the interest of an agent to walk purely sideways.\\

\noi For an agent coming from the other side, we used a function of the type
\begin{equation}\label{eq1}
	y(x) = \frac{1}{(|x-x_\y{Agent}|)^n}
\end{equation}
\noi and set the $y$ values corresponding to $x$ values on a collision course to zero. The exact implementation will be treated in chapter \textit{Implementation} where equation (\ref{eq1}) is modified to accommodate for various different parameters. If an agent has another agent in front of him which is walking in the same direction but slower, the function given in (\ref{eq1}) is also applied to overtake the slower agent.\\
Should another agent walk in the same direction, but with higher speed, we thought that it would be logical to follow him. This was done using a Gaussian curve centered on the direction of the faster agent.\\
Agents moving in the same direction with the same speed have no influence on each other in our model. Two agents standing still on the other hand will also be handled using the function given in (\ref{eq1}) to avoid standoffs.

\subsubsection{Necessary parameters and variables}
We reckon that the important parameters necessary to assess the influence of one agent onto the other agents are
\begin{itemize}
	\item $\alpha_X$, the angle between the centers of the two agents with respect to the y-axis
	\item $\Delta v$, the difference in velocity, set to be negative for this situation
	\item $\beta_\y{Links}$ and $\beta_\y{Rechts}$, two angles describing which directions of the path to be chosen would lead to a collision.
	\item $r_S = r_1 + r_2$ being the sum of the two involved agent's radii
	\item $d$, the distance between the two involved agents
\end{itemize}
\noi In figure \ref{fig:beta} (given in the implementation chapter) a graphical depiction of $\alpha_X$, $\beta_\y{Links}$ and $\beta_\y{Rechts}$ is given alongside the way to calculate them.\\
The sign of $\Delta v$ was chosen to be positive in the case of two agents walking in the same direction and negative in the case of crossing agents.

\subsubsection{Collision detection and the its connection to the iteration speed}
Collision detection has to be carried out in order to keep the simulation physically possible. We used an approach in which the vector describing the path the agent walks on is subdivided into several small steps. The agent then goes on as far as he can. To avoid the agents sticking too close together and therefore not being able to move anymore, the number of subdivisions should be rather small.\\
Given that the length of the vector is determined by the iteration time intervall $\Delta t$, it is also important for $\Delta t$ to be not too small. This has a phyiscal representation as in reality one goes on in discrete steps, not infinitesimally small steps that one would get in the case of $\Delta t \rightarrow 0$.

\subsection{Discretization}
As it is a numerical calculation, at some point there has to be a numerical discretization. Since we wanted the agents to be able to move around freely, we abandoned the idea of using a grid on which the agents could walk around in favour of a continuous space simulation. The discretization comes about in the form of the functions and angles to be calculated.

\subsection{Spawning of new agents}
A hallway usually has at its two endings a more open space than the hallway where the flow of people arriving from the hallway will disperse. In order for things not to get too messy, we decided that agents would simply cease to exist if they reach a line (called dstruction line) which would signify the beginning of this region of dispersion. Newly spawned agents would be created on a line (called spawn line) below the destruction line and pass a short distance without oncoming agents so that they could already orientate themselfes according to the flow of agents walking the other way. This could be important in cases where the agents would form columns and newly spawned agents could adapt to that by not interrupting the column.


